{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym import utils\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InventoryEnv(gym.Env, utils.EzPickle):\n",
    "    \"\"\"Inventory control with lost sales environment\n",
    "\n",
    "    TO BE EDITED\n",
    "\n",
    "    This environment corresponds to the version of the inventory control\n",
    "    with lost sales problem described in Example 1.1 in Algorithms for\n",
    "    Reinforcement Learning by Csaba Szepesvari (2010).\n",
    "    https://sites.ualberta.ca/~szepesva/RLBook.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n=100, k=5, c=2, h=2, p=3, lam=8):\n",
    "        self.n = n\n",
    "        self.action_space = spaces.Discrete(n)\n",
    "        self.observation_space = spaces.Discrete(n)\n",
    "        self.max = n\n",
    "        self.state = n\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.h = h\n",
    "        self.p = p\n",
    "        self.lam = lam\n",
    "\n",
    "        # Set seed\n",
    "        self._seed()\n",
    "\n",
    "        # Start the first round\n",
    "        self._reset()\n",
    "\n",
    "    def demand(self):\n",
    "        return np.random.poisson(self.lam)\n",
    "\n",
    "    def transition(self, x, a, d):\n",
    "        m = self.max\n",
    "        return max(min(x + a, m) - d, 0)\n",
    "\n",
    "    def reward(self, x, a, y):\n",
    "        k = self.k\n",
    "        m = self.max\n",
    "        c = self.c\n",
    "        h = self.h\n",
    "        p = self.p\n",
    "        r = -k * (a > 0) - c * max(min(x + a, m) - x, 0) - h * x + p * max(min(x + a, m) - y, 0)\n",
    "        return r\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def _step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        obs = self.state\n",
    "        demand = self.demand()\n",
    "        obs2 = self.transition(obs, action, demand)\n",
    "        self.state = obs2\n",
    "        reward = self.reward(obs, action, obs2)\n",
    "        done = 0\n",
    "        return obs2, reward, done, {}\n",
    "\n",
    "    def _reset(self):\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
